# üí¨ Chat Ollama (client) By Uriel

<p align="center">
  <img src="https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logo=ollama&logoColor=white" alt="Ollama Badge">
  <img src="https://img.shields.io/badge/HTML5-E34F26?style=for-the-badge&logo=html5&logoColor=white" alt="HTML5 Badge">
  <img src="https://img.shields.io/badge/CSS3-1572B6?style=for-the-badge&logo=css3&logoColor=white" alt="CSS3 Badge">
  <img src="https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black" alt="JavaScript Badge">
  <img src="https://img.shields.io/badge/Open%20Source-30A3DC?style=for-the-badge&logo=opensourceinitiative&logoColor=white" alt="Open Source Badge">
</p>

Uma interface de chat simples e eficiente para interagir com um servidor de Intelig√™ncia Artificial [Ollama](https://ollama.ai/). Desenvolvido em HTML, CSS e JavaScript puro, este projeto oferece uma maneira pr√°tica de conversar com seus modelos de linguagem locais, incluindo suporte para anexos de arquivos (texto e imagem) e configura√ß√µes avan√ßadas de gera√ß√£o de texto.

---

## ‚ú® Funcionalidades Principais

Este chat foi projetado para otimizar sua intera√ß√£o com modelos Ollama, oferecendo um controle detalhado sobre as configura√ß√µes e a entrada de dados:

*   **Conex√£o Flex√≠vel:** A URL da API Ollama pode ser facilmente configurada nas defini√ß√µes (`http://localhost:11434/api/chat` por padr√£o), permitindo a conex√£o a diferentes inst√¢ncias do Ollama.
*   **Sele√ß√£o Din√¢mica de Modelos:** O chat consulta automaticamente seu servidor Ollama para listar todos os modelos dispon√≠veis, permitindo que voc√™ selecione e alterne entre eles de forma intuitiva.
*   **Configura√ß√µes de Gera√ß√£o Avan√ßadas:** Controle fino sobre como o modelo gera suas respostas:
    *   **Tamanho do Contexto (`num_ctx`):** Ajuste o limite m√°ximo de tokens para o prompt de entrada, influenciando a "mem√≥ria" do modelo.
    *   **Comprimento M√°ximo da Resposta (`num_predict`):** Defina o n√∫mero m√°ximo de tokens para as respostas geradas pelo modelo.
    *   **Prompt do Sistema (`system`):** Personalize as instru√ß√µes iniciais que guiam o comportamento e a persona do modelo.
    *   **Mem√≥ria de Contexto:** Um controle para ativar ou desativar o uso do hist√≥rico da conversa, permitindo que o modelo mantenha ou ignore o contexto de intera√ß√µes anteriores.
*   **Presets de Gera√ß√£o:** Alterne rapidamente entre conjuntos de par√¢metros otimizados para diferentes tipos de intera√ß√£o:
    *   **"Conversa√ß√£o":** Ideal para di√°logos flu√≠dos e naturais.
    *   **"Programa√ß√£o":** Otimizado para gera√ß√£o e depura√ß√£o de c√≥digo.
    *   **"Criativo":** Favorece respostas mais imaginativas e originais (ideal para brainstorming).
    *   **"Padr√£o do Modelo":** Reseta os par√¢metros para as configura√ß√µes originais do modelo Ollama selecionado.
*   **Anexos de Arquivo:**
    *   **Documentos:** Suporte para anexar arquivos de texto (`.txt`, `.csv`) e PDFs. O conte√∫do dos PDFs √© automaticamente extra√≠do para ser analisado pelo modelo.
    *   **Imagens:** Permite anexar imagens (`.png`, `.jpeg`, `.gif`, `.webp`) para interagir com modelos multimodais (como o `llava`).
    *   √â poss√≠vel anexar at√© 5 arquivos por vez, desde que sejam da mesma categoria (texto ou imagem).
*   **Interface Intuitiva:**
    *   Exibi√ß√£o clara do hist√≥rico de mensagens do usu√°rio e do bot, renderizadas com formata√ß√£o Markdown para melhor legibilidade.
    *   Realce de sintaxe para blocos de c√≥digo e JSON nas respostas do bot.
    *   Barra de status que fornece feedback em tempo real sobre a conex√£o e as opera√ß√µes.
    *   Bot√£o "Copiar" para copiar facilmente as respostas formatadas do bot para a √°rea de transfer√™ncia.
*   **Ferramentas de Visualiza√ß√£o:**
    *   **"Ver √öltimo Envio":** Inspecione o JSON exato que foi enviado para a API Ollama na √∫ltima requisi√ß√£o, √∫til para depura√ß√£o.
    *   **"Informa√ß√µes do Modelo Selecionado":** Obtenha detalhes t√©cnicos e metadados sobre o modelo Ollama que est√° atualmente selecionado, diretamente do seu servidor Ollama.
*   **Gerenciamento do Chat:** Bot√£o para limpar todo o hist√≥rico de mensagens e redefinir as configura√ß√µes para os padr√µes.
*   **Design Responsivo:** A interface se adapta bem a diferentes tamanhos de tela, proporcionando uma experi√™ncia consistente em desktops e dispositivos m√≥veis.
*   **Persist√™ncia de Configura√ß√µes:** Suas configura√ß√µes preferidas s√£o salvas localmente no navegador, carregando automaticamente na pr√≥xima vez que voc√™ usar o chat.

---

## ÔøΩÔøΩ Como Usar

Para come√ßar a interagir com seus modelos Ollama atrav√©s desta interface de chat, voc√™ precisa ter o Ollama instalado e rodando.

### Pr√©-requisitos

*   **Ollama:** Certifique-se de ter o [Ollama](https://ollama.ai/) instalado e em execu√ß√£o em seu sistema, com um ou mais modelos de linguagem baixados.

### Execu√ß√£o

1.  **Baixe o arquivo `index.html`:** Fa√ßa o download do arquivo `index.html` para uma pasta de sua escolha em seu computador.
2.  **Abra o arquivo no navegador:** Simplesmente abra o arquivo `index.html` usando qualquer navegador web moderno de sua prefer√™ncia (Google Chrome, Mozilla Firefox, Microsoft Edge, Safari, etc.).
3.  **Configura√ß√£o Inicial:**
    *   Por padr√£o, o chat tentar√° se conectar √† API Ollama em `http://localhost:11434/api/chat`. Se a sua instala√ß√£o do Ollama estiver em um endere√ßo diferente, clique no bot√£o `‚öôÔ∏è Configura√ß√µes` (canto superior direito) e ajuste a `URL da API Ollama` conforme necess√°rio.
    *   Ap√≥s a conex√£o, o menu `Sele√ß√£o de Modelo` ser√° preenchido automaticamente com os modelos dispon√≠veis no seu servidor Ollama. Escolha o modelo com o qual deseja conversar.
4.  **Inicie a Conversa:** Digite sua mensagem na caixa de texto na parte inferior da tela e pressione `Enter` ou clique no bot√£o `Enviar`.

### Anexando Arquivos

1.  Para anexar arquivos √† sua mensagem, clique no bot√£o `Anexar` (üìé) ao lado da caixa de texto.
2.  Uma janela modal ser√° exibida, onde voc√™ pode arrastar e soltar arquivos ou clicar para navegar e selecion√°-los.
3.  Os arquivos selecionados aparecer√£o na lista. Clique em `Limpar Arquivos Anexados` se precisar remover algum.
4.  Ap√≥s anexar, os arquivos ser√£o enviados junto com a pr√≥xima mensagem que voc√™ enviar.

---

## üõ†Ô∏è Tecnologias Utilizadas

*   **HTML5:** A estrutura fundamental da p√°gina.
*   **CSS3:** Estiliza√ß√£o completa da interface, incluindo o uso de vari√°veis CSS para facilitar a personaliza√ß√£o de cores.
*   **JavaScript:** Toda a l√≥gica interativa do chat, comunica√ß√£o com a API Ollama, manipula√ß√£o do DOM e processamento de arquivos.
*   **[Marked.js](https://marked.js.org/):** Uma biblioteca JavaScript para renderizar respostas formatadas em Markdown.
*   **[PDF.js](https://mozilla.github.io/pdf.js/):** Uma biblioteca da Mozilla para leitura e extra√ß√£o de texto de arquivos PDF diretamente no navegador.

---

## ü§ù Contribui√ß√£o

Este projeto √© de c√≥digo aberto! Sua contribui√ß√£o √© bem-vinda para torn√°-lo ainda melhor. Se voc√™ tem ideias para novas funcionalidades, identificou um bug ou deseja melhorar o c√≥digo, por favor, siga os passos abaixo:

1.  Fa√ßa um **Fork** deste reposit√≥rio.
2.  Crie uma nova `branch` para suas altera√ß√µes: `git checkout -b feature/nome-da-sua-feature` ou `git checkout -b bugfix/correcao-de-bug`.
3.  Implemente suas mudan√ßas e fa√ßa commits descritivos.
4.  Envie sua `branch` para o seu reposit√≥rio forked: `git push origin feature/nome-da-sua-feature`.
5.  Abra um **Pull Request** para o reposit√≥rio original, descrevendo claramente suas altera√ß√µes.

Sua colabora√ß√£o √© muito apreciada!

---

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Para mais detalhes, consulte o arquivo [LICENSE](LICENSE) neste reposit√≥rio.

---

## üßë‚Äçüíª Autor

Desenvolvido por Uriel Gusm√£o Apol√¥nio.

---
